{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de E_in: 0.504046\n",
      "Desvio padrão de E_in: 0.0430424195881226\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função target\n",
    "def target_function(x1, x2):\n",
    "    return np.sign(x1**2 + x2**2 - 0.6)\n",
    "\n",
    "# Gerar dados com ruído\n",
    "def generate_data(N):\n",
    "    X = np.random.uniform(-1, 1, (N, 2))\n",
    "    y = target_function(X[:, 0], X[:, 1])\n",
    "    # Adicionar ruído a 10% dos pontos\n",
    "    num_noisy_points = int(N * 0.1)\n",
    "    noisy_indices = np.random.choice(N, num_noisy_points, replace=False)\n",
    "    y[noisy_indices] = -y[noisy_indices]\n",
    "    return X, y\n",
    "\n",
    "# Regressão Linear\n",
    "def linear_regression(X, y):\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Adicionar x0 = 1 para cada instância\n",
    "    w = np.linalg.pinv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "    return w\n",
    "\n",
    "# Calcular erro dentro da amostra\n",
    "def calculate_error(X, y, w):\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    predictions = np.sign(X_b.dot(w))\n",
    "    return np.mean(predictions != y)\n",
    "\n",
    "# Experimento\n",
    "def experiment(num_runs, num_points):\n",
    "    ein_list = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        X, y = generate_data(num_points)\n",
    "        w = linear_regression(X, y)\n",
    "        ein = calculate_error(X, y, w)\n",
    "        ein_list.append(ein)\n",
    "\n",
    "    return np.mean(ein_list), np.std(ein_list)\n",
    "\n",
    "# Parâmetros\n",
    "num_runs = 1000\n",
    "num_points = 1000\n",
    "\n",
    "# Executar o experimento\n",
    "mean_ein, std_ein = experiment(num_runs, num_points)\n",
    "print(f\"Média de E_in: {mean_ein}\")\n",
    "print(f\"Desvio padrão de E_in: {std_ein}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos médios após 1000 execuções: [-9.90877673e-01 -8.89700181e-04 -7.74980809e-04 -3.18832446e-03\n",
      "  1.55341036e+00  1.55983317e+00]\n",
      "Distância da hipótese a: 0.18218518227437255\n",
      "Distância da hipótese b: 13.441268387683179\n",
      "Distância da hipótese c: 13.447717711895802\n",
      "Distância da hipótese d: 2.609888417481193\n",
      "Distância da hipótese e: 2.4951522969439326\n",
      "Hipótese mais próxima: a\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função target\n",
    "def target_function(x1, x2):\n",
    "    return np.sign(x1**2 + x2**2 - 0.6)\n",
    "\n",
    "# Gerar dados com ruído\n",
    "def generate_data(N, noise_ratio):\n",
    "    X = np.random.uniform(-1, 1, (N, 2))\n",
    "    y = target_function(X[:, 0], X[:, 1])\n",
    "    # Adicionar ruído a 10% dos pontos\n",
    "    num_noisy_points = int(N * noise_ratio)\n",
    "    noisy_indices = np.random.choice(N, num_noisy_points, replace=False)\n",
    "    y[noisy_indices] = -y[noisy_indices]\n",
    "    return X, y\n",
    "\n",
    "# Transformar os dados\n",
    "def transform_data(X):\n",
    "    x1, x2 = X[:, 0], X[:, 1]\n",
    "    X_transformed = np.c_[np.ones(X.shape[0]), x1, x2, x1 * x2, x1**2, x2**2]\n",
    "    return X_transformed\n",
    "\n",
    "# Regressão Linear\n",
    "def linear_regression(X, y):\n",
    "    w = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return w\n",
    "\n",
    "# Experimento\n",
    "def experiment(num_runs, num_points):\n",
    "    weights_list = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        \n",
    "        X, y = generate_data(num_points, noise_ratio=0.1)\n",
    "        X_transformed = transform_data(X)\n",
    "        w = linear_regression(X_transformed, y)\n",
    "        weights_list.append(w)\n",
    "\n",
    "    weights_mean = np.mean(weights_list, axis=0)\n",
    "    return weights_mean\n",
    "\n",
    "# Parâmetros\n",
    "num_runs = 1000\n",
    "num_points = 1000\n",
    "\n",
    "# Executar o experimento\n",
    "weights_mean = experiment(num_runs, num_points)\n",
    "print(f\"Pesos médios após 1000 execuções: {weights_mean}\")\n",
    "\n",
    "# Hipóteses fornecidas\n",
    "hypotheses = {\n",
    "    \"a\": np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5]),\n",
    "    \"b\": np.array([-1, -0.05, 0.08, 0.13, 1.5, 15]),\n",
    "    \"c\": np.array([-1, -0.05, 0.08, 0.13, 15, 1.5]),\n",
    "    \"d\": np.array([-1, -1.5, 0.08, 0.13, 0.05, 0.05]),\n",
    "    \"e\": np.array([-1, -0.05, 0.08, 1.5, 0.15, 0.15]),\n",
    "}\n",
    "\n",
    "# Comparar pesos médios encontrados com as hipóteses fornecidas\n",
    "for key, hypothesis in hypotheses.items():\n",
    "    distance = np.linalg.norm(weights_mean - hypothesis)\n",
    "    print(f\"Distância da hipótese {key}: {distance}\")\n",
    "\n",
    "# Encontre a hipótese mais próxima\n",
    "closest_hypothesis = min(hypotheses, key=lambda k: np.linalg.norm(weights_mean - hypotheses[k]))\n",
    "print(f\"Hipótese mais próxima: {closest_hypothesis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(num_runs, num_points_train, num_points_test):\n",
    "    eout_list = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        # Dados de treinamento\n",
    "        X_train, y_train = generate_data(num_points_train, noise_ratio=0.1)\n",
    "        X_train_transformed = transform_data(X_train)\n",
    "        w = linear_regression(X_train_transformed, y_train)\n",
    "        \n",
    "        # Dados de teste\n",
    "        X_test, y_test = generate_data(num_points_test, noise_ratio=0.0)\n",
    "        X_test_transformed = transform_data(X_test)\n",
    "        eout = calculate_error(X_test_transformed, y_test, w)\n",
    "        \n",
    "        eout_list.append(eout)\n",
    "\n",
    "    return np.mean(eout_list), np.std(eout_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média de E_out: 0.032398\n",
      "Desvio padrão de E_out: 0.011196320645640693\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Função target\n",
    "def target_function(x1, x2):\n",
    "    return np.sign(x1**2 + x2**2 - 0.6)\n",
    "\n",
    "# Gerar dados com ruído\n",
    "def generate_data(N, noise_ratio=0.1):\n",
    "    X = np.random.uniform(-1, 1, (N, 2))\n",
    "    y = target_function(X[:, 0], X[:, 1])\n",
    "    # Adicionar ruído a 10% dos pontos\n",
    "    num_noisy_points = int(N * noise_ratio)\n",
    "    noisy_indices = np.random.choice(N, num_noisy_points, replace=False)\n",
    "    y[noisy_indices] = -y[noisy_indices]\n",
    "    return X, y\n",
    "\n",
    "# Transformar os dados\n",
    "def transform_data(X):\n",
    "    x1, x2 = X[:, 0], X[:, 1]\n",
    "    X_transformed = np.c_[np.ones(X.shape[0]), x1, x2, x1 * x2, x1**2, x2**2]\n",
    "    return X_transformed\n",
    "\n",
    "# Regressão Linear\n",
    "def linear_regression(X, y):\n",
    "    w = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return w\n",
    "\n",
    "# Calcular erro fora da amostra\n",
    "def calculate_eout(X, y, w):\n",
    "    predictions = np.sign(X.dot(w))\n",
    "    return np.mean(predictions != y)\n",
    "\n",
    "# Experimento\n",
    "def experiment(num_runs, num_points_train, num_points_test):\n",
    "    eout_list = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        # Dados de treinamento\n",
    "        X_train, y_train = generate_data(num_points_train)\n",
    "        X_train_transformed = transform_data(X_train)\n",
    "        w = linear_regression(X_train_transformed, y_train)\n",
    "        \n",
    "        # Dados de teste\n",
    "        X_test, y_test = generate_data(num_points_test, noise_ratio=0.0)\n",
    "        X_test_transformed = transform_data(X_test)\n",
    "        eout = calculate_eout(X_test_transformed, y_test, w)\n",
    "        \n",
    "        eout_list.append(eout)\n",
    "\n",
    "    return np.mean(eout_list), np.std(eout_list)\n",
    "\n",
    "# Parâmetros\n",
    "num_runs = 1000\n",
    "num_points_train = 1000\n",
    "num_points_test = 1000\n",
    "\n",
    "# Executar o experimento\n",
    "mean_eout, std_eout = experiment(num_runs, num_points_train, num_points_test)\n",
    "print(f\"Média de E_out: {mean_eout}\")\n",
    "print(f\"Desvio padrão de E_out: {std_eout}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
