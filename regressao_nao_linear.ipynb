{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from module import generate_data, calculate_error, non_linear_target_function, linear_regression, pocket_pla, transform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Linear Regression\n",
    "Do 1000 executions of:\n",
    "1. Choose a target function.\n",
    "2. Generate 1000 points data from the distribution $(X \\in [1, -1] \\times [1, -1])$ and classify it with the target function.\n",
    "3. Randomly select 10% of the points and invert their labels\n",
    "4. Run the Linear Regression algorithm and the Linear Regression algorithm with transformation\n",
    "5. Evaluate on a set of 1000 test points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Linear Regression without any transformation, using the vector of attributes(1, x2, x2) to find the weight w. What is the approximate classification value of the average within-sample error Ein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ein mean: 0.503842\n",
      "Ein std: 0.04336758047205309\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Experimento\n",
    "def experiment(num_runs, num_points):\n",
    "    ein_list = []\n",
    "    for _ in range(num_runs):\n",
    "        nlg_tg = non_linear_target_function()\n",
    "        X, y = generate_data(num_points, nlg_tg, noise_ratio=0.1)\n",
    "        w = linear_regression(X, y) \n",
    "        ein = calculate_error(X, y, w)\n",
    "        ein_list.append(ein)\n",
    "\n",
    "    return np.mean(ein_list), np.std(ein_list)\n",
    "\n",
    "# Parâmetros\n",
    "num_runs = 1000\n",
    "num_points = 1000\n",
    "\n",
    "# Executar o experimento\n",
    "mean_ein, std_ein = experiment(num_runs, num_points)\n",
    "print(f\"Ein mean: {mean_ein}\")\n",
    "print(f\"Ein std: {std_ein}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, transform the N = 1000 training data following the non-linear attribute vector $(1, x_1, x_2, x_1x_2, x_1^2, x_2^2)$. Find the vector we that corresponds to the solution of the Linear Regression. Which of the following hypotheses is closest to the one you found? Evaluate the average result obtained after 1000 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos médios após 1000 execuções: [-9.93674961e-01 -1.89048351e-04 -1.60788732e-03 -2.11801643e-03\n",
      "  1.56264407e+00  1.55677400e+00]\n",
      "Distância da hipótese a: 0.18380348602705293\n",
      "Distância da hipótese b: 13.4443626008241\n",
      "Distância da hipótese c: 13.43846694159698\n",
      "Distância da hipótese d: 2.6138186417175238\n",
      "Distância da hipótese e: 2.4980223943156386\n",
      "Hipótese mais próxima: a\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def experiment(num_runs, num_points):\n",
    "    weights_list = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        nlg_tg = non_linear_target_function()\n",
    "        X, y = generate_data(num_points, nlg_tg, noise_ratio=0.1)\n",
    "        X_transformed = transform_data(X)\n",
    "        w = linear_regression(X_transformed, y)\n",
    "        weights_list.append(w)\n",
    "\n",
    "    weights_mean = np.mean(weights_list, axis=0)\n",
    "    return weights_mean\n",
    "\n",
    "num_runs = 1000\n",
    "num_points = 1000\n",
    "\n",
    "\n",
    "weights_mean = experiment(num_runs, num_points)\n",
    "print(f\"Pesos médios após 1000 execuções: {weights_mean}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hipóteses fornecidas\n",
    "hypotheses = {\n",
    "    \"a\": np.array([-1, -0.05, 0.08, 0.13, 1.5, 1.5]),\n",
    "    \"b\": np.array([-1, -0.05, 0.08, 0.13, 1.5, 15]),\n",
    "    \"c\": np.array([-1, -0.05, 0.08, 0.13, 15, 1.5]),\n",
    "    \"d\": np.array([-1, -1.5, 0.08, 0.13, 0.05, 0.05]),\n",
    "    \"e\": np.array([-1, -0.05, 0.08, 1.5, 0.15, 0.15]),\n",
    "}\n",
    "\n",
    "# Comparar pesos médios encontrados com as hipóteses fornecidas\n",
    "for key, hypothesis in hypotheses.items():\n",
    "    distance = np.linalg.norm(weights_mean - hypothesis)\n",
    "    print(f\"Distância da hipótese {key}: {distance}\")\n",
    "\n",
    "# Encontre a hipótese mais próxima\n",
    "closest_hypothesis = min(hypotheses, key=lambda k: np.linalg.norm(weights_mean - hypotheses[k]))\n",
    "print(f\"Hipótese mais próxima: {closest_hypothesis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the closest value of the out-of-sample classification error Eout to your hypothesis in the previous question? (Estimate it by generating a new set of 1000 points and using 1000 different runs, as before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(num_runs, num_points_train, num_points_test):\n",
    "    eout_list = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        # Dados de treinamento\n",
    "        nlg_tg = non_linear_target_function()\n",
    "        X_train, y_train = generate_data(num_points_train, nlg_tg, noise_ratio=0.1)\n",
    "        X_train_transformed = transform_data(X_train)\n",
    "        w = linear_regression(X_train_transformed, y_train)\n",
    "        \n",
    "        # Dados de teste\n",
    "        X_test, y_test = generate_data(num_points_test,nlg_tg, noise_ratio=0.1)\n",
    "        X_test_transformed = transform_data(X_test)\n",
    "        eout = calculate_error(X_test_transformed, y_test, w)\n",
    "        \n",
    "        eout_list.append(eout)\n",
    "\n",
    "    return np.mean(eout_list), np.std(eout_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eout mean: 0.126011\n",
      "Eout std: 0.009901862400578994\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros\n",
    "num_runs = 1000\n",
    "num_points_train = 1000\n",
    "num_points_test = 1000\n",
    "\n",
    "# Executar o experimento\n",
    "mean_eout, std_eout = experiment(num_runs, num_points_train, num_points_test)\n",
    "print(f\"Eout mean: {mean_eout}\")\n",
    "print(f\"Eout std: {std_eout}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
